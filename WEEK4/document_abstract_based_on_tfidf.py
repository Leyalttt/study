import jieba
import re
import json
from calculate_tfidf import calculate_tfidf, tf_idf_topk

"""
基于tfidf实现简单文本摘要
"""

jieba.initialize()


# 加载文档数据（可以想象成网页数据），计算每个网页的tfidf字典
def load_data(file_path):
    corpus = []
    # [
    #   {
    #     "title": "叠穿：越多穿越瘦是可能的（组图）",
    #     "content": "编者按：今年冬季让叠穿打造你的完美身材，越穿越瘦是可能。哪怕是不了解流行，也要对时尚又显瘦的叠穿造型吸引，现在就开始行动吧！搭配Tips：亮红色的皮外套给人光彩夺目的感觉，内搭短版的黑色T恤，露出带有线条的腹部是关键，展现你健美的身材。 搭配Tips：简单款型的机车装也是百搭的单品，内搭一条长版的连衣裙打造瘦身的中性装扮。软硬结合的mix风同样备受关注。 搭配Tips：贴身的黑色装最能达到瘦身的效果，即时加上白色的长外套也不会发福。长款的靴子同样很好的修饰了你的小腿线条。 搭配Tips：高腰线的抹胸装很有拉长下身比例的效果，A字形的荷叶摆同时也能掩盖腰部的赘肉。外加一件短款的羽绒服，配上贴腿的仔裤，也很修长。"
    #   },
    #   {
    #     "title": "四十五度皮草广场蓝色港湾旗舰店周年庆典",
    #     "content": "2010年10月对于一个深谙北京商业讯息的人来说，这代表了四十五度皮草广场蓝色港湾店将迎来她的1岁生日；10月——对于四十五度皮草人来说，是华美变身的一天，从这天起，这座集结了众多国内外皮草品牌的购物广场将由蓝色港湾商圈这艘巨轮载着驶向更加华美的航程。从今天起，蓝色港湾——这个积聚众多品牌的商圈，藉由四十五度皮草广场的周年庆之际，将上演一场华美的店庆皮草“饕餮盛宴”：KC皮草、玛沙拉蒂皮草、兽王、月亮石、谷子、冬品梅、雪豹、冬威国内外等数知名皮草，波司登、雪中飞等知名羽绒品牌加入，给商圈增添了新的生机和活力，为四十五度广场再谱华丽乐章。新的新品牌参与度100%，给消费者更加尊贵的享受。活力四射的欧洲当季时尚款式皮草，时尚、休闲化的羽绒服将给消费者一个温暖如春的冬季，让时尚达人们翘首以待。解构四十五度皮草广场不少人还记得四十五度皮草广场一年前开业盛典的情形：衣香鬓影，名流云集，由名模张信哲、岳梅领衔，20位身着当季最新皮革皮草服装的男女模特从广场台阶上依次走下，或华丽尊贵，或轻巧灵动，颠覆了以往人们对于皮草服饰的传统概念，为2009年秋季的欧式风格广场平添顶级时尚风韵。皮草一直是时尚界的致命诱惑，一袭皮草，万种风情，其华丽雍容的气质，随时随地无不彰显的高雅与风华，都令时尚女性魂牵梦萦，爱不释手。尽管吸引力足够大，很多人还是望而却步，究其原因一是觉得皮草一定价格昂贵，二是觉得款式不够新颖，三是不太懂得专业知识，怕买时上当，品质无法保障。而这些问题，在四十五度皮草广场都会得到完美解决。从产品上看，四十五度皮草广场引进了许多欧洲当季时尚款式皮草服装，色彩上比较跳跃丰富，不同于以往市场上传统皮草服装面貌。品质上，原料均来自美国和北欧世家的顶级皮草，并且由于是专业人士采购，与商场代销模式造成的品质良莠不齐相比，可以加强对于皮草等级的把控，消除了消费者的心理上对于质量的疑虑。品牌上，集中的大卖场式皮草广场的概念一经推出，便应者如云，得到许多知名品牌的支持。最为贴心的是售后服务方面，据悉，四十五度皮草广场将建立专业的售后服务系统，彻底解决消费者缺少专业知识保养皮革皮草的问题，一旦购买，就多了一位贴心信服的保养顾问。有这样的品质保障，那么价格方面呢？应该说最具诱惑力的就是价格了，由于是集中采购和买断款式，减去了批发流通环节，也不需要厂家负担店面和销售费用，从厂家直接供货给消费者，所以价格上至少比其他大商场同等质量的产品便宜三分之一。四十五度，是仰视的角度，暗示着以往皮草作为昂贵的服饰材料，给消费者可望不可及的印象；四十五度，是从水平面向上前行的角度，说明了不断进步，始终以高品质服务于消费者的信心和决心；四十五度，又是一个相对来说前卫抽象的概念，迎合了年轻消费者喜欢新奇，永远求变的心态，彰显出年轻、时尚、活泼、另类的风格。血拼达人在四十五度的典型35岁的祝薇就住在朝阳，这两年的闲散时光几乎都在蓝色港湾度过，她这样描述了她的“典型”感受——漫步在蓝色港湾的欧洲小镇街头，听喷泉轻唱，看水波荡漾，空气中都能感受到优雅时尚的气息。“通常我会重点逛四十五度，因为那里品牌比较集中，而且价格适中。 皮草通常给人昂贵的感觉，以前我也是这么认为。但是熟悉了四十五度，我就知道这里给人尊贵感的皮草还拥有比较适合的价格，当然价格是一方面，我更中意时尚另类的风格。”受众多买家的追捧，更多品牌的加盟与时尚、潮流的定位都让这座旗舰店焕发出巨大新鲜感和吸引力。“四十五度满足了型男索女们对时尚、潮流的所要需求”，四十五度负责人这样表达，位于蓝色港湾楼美瑞百货二层的四十五度皮草广场占地2000平米，店内风格清新大气，云集国内外几十家皮革皮草名牌，上千种款式，是目前北京面积最大、集中品牌最多的第一家专门经营皮草皮革皮具的高端卖场。四十五度皮草广场所售卖的并不仅仅是商品，更有关乎文化的、精神层面的，甚至是一种全新的生活方式。随着蓝色港湾旗舰店的正式开业，四十五度皮草广场表明了自己在皮草销售领域走专业化、规模化、直销化、年轻化的态度和定位。接下来，四十五度皮草广场将在北京开2-3家分店，之后辐射到华北、东北、华东等地，形成连锁专营店的强大优势。“家电领域有苏宁、国美，皮草领域有四十五度”。今年，四十五度1岁了。年轻的她充满了自信与活力。希望，接下来的每一个生日，四十五度都能给我们带来莫大的惊喜。"
    #   },
    #   {
    #     "title": "改善城南旧面貌 湿地公园高速周边觅新盘",
    #     "content": "新浪房产讯（编辑 李旭冉）2009年11月北京34个部门和城南五区共同参与制定的北京市《促进城市南部地区加快发展行动计划》正式对外发布。除了将用3年时间向崇文、宣武、丰台、房山和大兴投入2900亿元资金外，还首次提出打造“一轴一带多园区”的城南产业发展格局。南城楼市将急剧升温。当下为了改善城南地区落后的交通面貌，北京市投资108亿元，启动了7条大通道建设。其中，京良快速路、京石二通道、马西路南延以及丰台的煤市口路西延明年都将开工建设，预计2至3年即可全面建成通车。煤市口路西延从玉泉路横跨永定河直达长兴路，位于莲石路和京石高速之间，建成后能够分流东西向15%的交通量，缓解京石高速堵车现象。结合城南生态环境改善，明年还将启动南中轴森林公园和三海子湿地公园二期的建设。今天小编就给大家推荐几个在这范围内的项目。中信新城（论坛 相册 户型 样板间 点评 地图搜索）项目位于亦庄经济技术开发区三海子东路，预计2010年年底或2011年年初入市，目前均价待定，待售户型为80-90平米二居、90-160平米三居、180-220平米四居，部分精装修，预计2013年4月入住。项目地处亦庄新城核心区域，以板楼为主。中信新城项目紧邻东南五环，位于亦庄核心生活区西侧，是亦庄核心生活区里最后一块住宅用地，同时也是唯一包含在“南海子公园”整体规划内的居住项目。“南海子公园”占地面积11.65平方公里（15000亩），相当于4个朝阳公园。中信新城项目周边配套设施齐备，生活、教育、医疗、休闲娱乐等设施一应俱全；项目整体规划达到170万平米，西北两侧和东侧分别被南海子郊野公园和凉水河紧紧环抱，与南海子公园形成双公园辉映，是低碳宜居生活的首选。以上信息仅供参考，最终以开发商公布为准。本稿件为新浪乐居独家原创稿件，版权所有，引用或转载请注明出处。点击查看更多打折优惠楼盘信息点击查看最新楼盘户型展示我要评论房产导航："
    #   }
    #   ]
    with open(file_path, encoding="utf8") as f:
        documents = json.loads(f.read())
        for document in documents:
            # 对于每个文档，检查其标题和内容是否包含换行符\n，如果不包含，则将标题和内容连接起来
            assert "\n" not in document["title"]
            assert "\n" not in document["content"]
            corpus.append(document["title"] + "\n" + document["content"])
        # print('corpus', corpus)  # corpus ['叠穿：越多穿越瘦是可能的（组图）\n编者按：今年冬季让叠穿打造你的完美身材，
        tf_idf_dict = calculate_tfidf(corpus)
        # print('tf_idf_dict', tf_idf_dict)  # {0:{'换发': 0.01559446501768832, '金融': 0.021522636267003663}...12:{......}}
        # print('tf_idf_dict', len(tf_idf_dict))  # 360个title和content的对象

    return tf_idf_dict, corpus


# 计算每一篇文章的摘要
# 输入该文章的tf_idf词典，和文章内容
# top为人为定义的选取的句子数量
# 过滤掉一些正文太短的文章，因为正文太短在做摘要意义不大

# document_tf_idf是当前title和content的tfidf, document是当前的content
def generate_document_abstract(document_tf_idf, document, top=3):
    #
    # print('document_tf_idf', document_tf_idf) # {'哈勃': 0.1773145089919276, '望远镜': 0.047518512433511725, '重新': 0.030562331283566738,
    # 使用正则表达式 re.split("？|！|。", document) 将document拆分为句子列表 sentences
    sentences = re.split("？|！|。", document)
    # 过滤掉正文在五句以内的文章
    if len(sentences) <= 5:
        return None
    result = []
    # index content中的第几句话, 第几句话的内容是sentence
    for index, sentence in enumerate(sentences):
        sentence_score = 0
        # 对句子进行分词
        words = jieba.lcut(sentence)
        # print('words', words)  #  ['一般', '情况', '下', '为', ':', '影院', '50%', '左右',
        for word in words:
            # 每个词，如果它在document_tf_idf当前字典中存在(不是最外层的tfidf)，则将其对应的值加到sentence_score上
            # word一个分词
            sentence_score += document_tf_idf.get(word, 0)
        sentence_score /= (len(words) + 1)
        # 你每句话都有分数
        result.append([sentence_score, index])
    # 对当前这个content中的每句话的得分进行排序, 降序
    result = sorted(result, key=lambda x: x[0], reverse=True)
    # print('result', result)  # [[0.024197315135373654, 3], [0.02267752600050611, 5], [0.0225956634025212, 0], [0.020735343528007665, 2], [0.019448467244185873, 7]
    # 权重最高的可能依次是第10，第6，第3句，将他们调整为出现顺序比较合理，即3,6,10, 并返回x[1] 下标
    important_sentence_indexs = sorted([x[1] for x in result[:top]])
    # 返回当前content的得分最多高的前三句话进行拼接
    return "。".join([sentences[index] for index in important_sentence_indexs])


# 生成所有文章的摘要
# corpus 所有的title和content的拼接
def generate_abstract(tf_idf_dict, corpus):
    res = []
    # index是当前第几个title和content的组合, document_tf_idf是当前title和content组合分词的tfidf
    for index, document_tf_idf in tf_idf_dict.items():
        # 对当前的title和content的组合通过换行符进行分割
        title, content = corpus[index].split("\n")
        if index == 0:
            print('content', content)
        abstract = generate_document_abstract(document_tf_idf, content)
        # print("abstract", abstract)  # 编者按：今年冬季让叠穿打造你的完美身材，越穿越瘦是可能。 搭配Tips：简单款型的机车装也是百搭的单品，内搭一条长版的连衣裙打造瘦身的中性装扮。 搭配Tips：贴身的黑色装最能达到瘦身的效果，即时加上白色的长外套也不会发福
        if abstract is None:
            continue
        # 和index个title和content拼接上abstract
        corpus[index] += "\n" + abstract
        res.append({"标题": title, "正文": content, "摘要": abstract})
    return res


if __name__ == "__main__":
    path = "news.json"
    tf_idf_dict, corpus = load_data(path)
    res = generate_abstract(tf_idf_dict, corpus)
    # print('res', res)
    # writer = open("abstract.json", "w", encoding="utf8")
    # writer.write(json.dumps(res, ensure_ascii=False, indent=2))
    # writer.close()
    # deepseek推荐安全用法
    with open("abstract.json", "w", encoding="utf8") as f:
        json.dump(res, f, ensure_ascii=False, indent=2)
